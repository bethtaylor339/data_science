{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"image-processing-files/test_images/\"\n",
    "output_dir = \"image-processing-files/results/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 images for comparison.\n",
    "#image 5 because got a large bit of brightness noise, but other than that reasonably dark\n",
    "im05= cv2.imread('image-processing-files/test_images/im05-RET039OD.jpg', cv2.IMREAD_COLOR)\n",
    "#image 27 because bright and salt and pepper noise\n",
    "im27= cv2.imread('image-processing-files/test_images/im27-RET051OD.jpg', cv2.IMREAD_COLOR)\n",
    "#image 12 because lack of contrast and different noise \n",
    "im12= cv2.imread('image-processing-files/test_images/im12-RET137OD.jpg', cv2.IMREAD_COLOR)\n",
    "#image 3 goes black screen after warping and inpainting:\n",
    "im03= cv2.imread('image-processing-files/test_images/im03-RET033OD.jpg', cv2.IMREAD_COLOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_dir):\n",
    "    img = cv2.imread(os.path.join(input_dir, filename))\n",
    "    hist = cv2.calcHist([img], [0], None, [256], [0,256])\n",
    "    plt.xlabel('Pixel value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram of pixel values for all images')\n",
    "    plt.plot(hist)\n",
    "plt.savefig('Pixel values histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colour = ('b','g','r')\n",
    "for filename in os.listdir(input_dir):\n",
    "    img = cv2.imread(os.path.join(input_dir, filename))\n",
    "    if img is not None:  # Add this check\n",
    "        for i,col in enumerate(colour):\n",
    "            histr = cv2.calcHist([img],[i],None,[255],[1,255])\n",
    "            plt.plot(histr,color = col)\n",
    "            plt.xlim([1,256])\n",
    "            plt.xlabel('Pixel value')\n",
    "            plt.ylabel('Count')\n",
    "        \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inpainting finally works!!!!!\n",
    "processed_imgs = []\n",
    "for img in [im05, im12, im27, im03]:\n",
    "    mask = np.zeros_like(img[:,:,0])\n",
    "    center = (188, 212)\n",
    "    radius = 22\n",
    "    cv2.circle(mask, center, radius, 255, -1)\n",
    "\n",
    "    # Extract a similar section from the image\n",
    "    section = img[120:160, 190:230]\n",
    "\n",
    "    # Resize the mask to match the size of the image using interpolation\n",
    "    mask_resized = cv2.resize(mask, img.shape[:2][::-1], interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    # Inpaint the corrupted region in the color image using the extracted section\n",
    "    inpainted_color = cv2.inpaint(img, mask_resized, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Resize the section to match the size of the inpainted region\n",
    "    section_resized = cv2.resize(section, inpainted_color.shape[:2][::-1], interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "    # Replace the inpainted region with the extracted section\n",
    "    processed_img = inpainted_color.copy()\n",
    "    processed_img[mask_resized != 0] = section_resized[mask_resized != 0]\n",
    "\n",
    "    # Append the processed image to the list\n",
    "    processed_imgs.append(processed_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dewarping and removing borders 1\n",
    "dewarped = []\n",
    "for img in processed_imgs:\n",
    "    img=img\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(gray, 10, 255, 0)\n",
    "\n",
    "    plt.imshow(thresh)\n",
    "    plt.show()\n",
    "    #dewarping and removing borders 2\n",
    "    # finding the contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE,\n",
    "                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # take the first contour\n",
    "    cnt = contours[0]\n",
    "\n",
    "    rect = cv2.minAreaRect(cnt)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int0(box)\n",
    "    box_img = cv2.drawContours(img, [box], 0, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the result\n",
    "    plt.imshow(box_img)\n",
    "    plt.show()\n",
    "    #dewarping and removing borders 3\n",
    "\n",
    "    extent = np.float32([[0,0], [255,0], [255,255], [0,255]])\n",
    "    bounds = np.float32(box)\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(bounds, extent)\n",
    "\n",
    "    # Apply the transformation to the image\n",
    "    result = cv2.warpPerspective(img, M, (256, 256))\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    # Show the result\n",
    "    plt.imshow(result)\n",
    "    plt.show()\n",
    "    dewarped.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in dewarped:\n",
    "    img= cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Create a structuring element for morphological operations\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "    # Apply dilation to the image\n",
    "    dilation = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "    # Apply opening to the image\n",
    "    opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Apply closing to the image\n",
    "    closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    #Apply median to the image \n",
    "    median = cv2.medianBlur(img, 5)\n",
    "\n",
    "    # Apply bilateral to the image\n",
    "    bilateral = cv2.bilateralFilter((img),3,75,75)\n",
    "\n",
    "    # Display the original and processed images\n",
    "    cv2.imshow('Original Image', img)\n",
    "    cv2.imshow('Dilation', dilation)\n",
    "    cv2.imshow('Opening', opening)\n",
    "    cv2.imshow('Closing', closing)\n",
    "    cv2.imshow('Median', median)\n",
    "    cv2.imshow('Bilateral', bilateral)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median\n",
    "median_list = []\n",
    "for img in dewarped:\n",
    "    median = cv2.medianBlur(img, 5)\n",
    "    plt.imshow(median)\n",
    "    plt.show()\n",
    "    median_list.append(median)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = []\n",
    "for img in contrast_list:\n",
    "    # Convert the image to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Split the LAB image into separate channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(lab)\n",
    "\n",
    "    # Normalize the L channel to increase contrast\n",
    "    l_channel = cv2.normalize(l_channel, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "    # Adjust the brightness of the A and B channels\n",
    "    a_channel = cv2.addWeighted(a_channel, 0.9, np.mean(a_channel), 0, 0)\n",
    "    b_channel = cv2.addWeighted(b_channel, 0.9, np.mean(b_channel), 0, 0)\n",
    "\n",
    "    # Merge the channels back into a single LAB image\n",
    "    lab = cv2.merge([l_channel, a_channel, b_channel])\n",
    "\n",
    "    # Convert the LAB image back to BGR color space\n",
    "    balanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Display the original and balanced images side-by-side\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(balanced)\n",
    "    plt.show()\n",
    "    color_list.append(balanced)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN PIXEL VALUE FOR BRIGHTNESS\n",
    "\n",
    "#almost no need for colour changing- just ruining my results\n",
    "# Define the directory containing the images\n",
    "\n",
    "# Define the target mean pixel value\n",
    "target_mean = 120\n",
    "contrast_list=[]\n",
    "# Loop over all images in the directory\n",
    "for img in median_list:\n",
    "    # Load the image and convert to grayscale\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the mean pixel value\n",
    "    mean_pixel = np.mean(gray)\n",
    "\n",
    "    # Compute the scale factor\n",
    "    scale_factor = target_mean / mean_pixel\n",
    "    difference = abs(target_mean-mean_pixel)\n",
    "    # Adjust the contrast and brightness\n",
    "    adjusted = cv2.convertScaleAbs(img, alpha=scale_factor, beta=difference)\n",
    "\n",
    "    # Save the adjusted image\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(adjusted)\n",
    "    plt.show()\n",
    "    contrast_list.append(adjusted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in contrast_list:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    # Increase the contrast and brightness\n",
    "    alpha = 0.4 # Contrast control (1.0-3.0)\n",
    "    beta = 60  # Brightness control (0-100)\n",
    "    adjusted = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "\n",
    "    # Display the original and adjusted images side-by-side\n",
    "    cv2.imshow('Original', img)\n",
    "    cv2.imshow('Adjusted', adjusted)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in median_list:\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(gray, 10, 50)\n",
    "\n",
    "    # Apply Gaussian blur to remove noise\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "    # Create a sharpening filter\n",
    "    kernel = np.array([[-1,-1,-1],\n",
    "                    [-1, 9,-1],\n",
    "                    [-1,-1,-1]])\n",
    "\n",
    "    # Apply the unsharp masking filter to the edges only\n",
    "    sharp_edges = cv2.bitwise_and(blur, blur, mask=edges)\n",
    "    sharp_edges = cv2.filter2D(sharp_edges, -1, kernel)\n",
    "\n",
    "    # Combine the sharpened edges with the original image\n",
    "    result = cv2.addWeighted(img, 2, sharp_edges, -0.5, 0)\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    # Display the result\n",
    "    cv2.imshow('Original Image', img)\n",
    "    cv2.imshow('Sharpened Image with Edges', result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in median_list:\n",
    "    gamma = 3.0\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype('uint8')\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    # Apply the exponential transform to the image\n",
    "    img_enhanced = cv2.LUT(img, table)\n",
    "    \n",
    "    # Save the enhanced image to disk\n",
    "\n",
    "    cv2.imshow('Edges',img_enhanced )\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in median_list:\n",
    "    # Convert the image to the LAB color space\n",
    "    img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Split the LAB image into separate channels\n",
    "    l_channel, a_channel, b_channel = cv2.split(img_lab)\n",
    "\n",
    "    # Apply adaptive histogram equalization to the L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    l_channel_eq = clahe.apply(l_channel)\n",
    "\n",
    "    # Merge the equalized L channel with the original A and B channels\n",
    "    img_lab_eq = cv2.merge((l_channel_eq, a_channel, b_channel))\n",
    "\n",
    "    # Convert the image back to the original color space\n",
    "    img_output = cv2.cvtColor(img_lab_eq, cv2.COLOR_LAB2RGB)\n",
    "    cv2.imshow('Edges',img_output)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in median_list:\n",
    "    # gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Perform unsharp masking\n",
    "    blurred_img = cv2.GaussianBlur(img, (0, 0), 5)\n",
    "    mask = cv2.subtract(img, blurred_img)\n",
    "    unsharp_img = cv2.addWeighted(img, 1.5, mask, 0, 0)\n",
    "    # Convert back to color\n",
    "    color_img = cv2.cvtColor(unsharp_img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('Edges',color_img )\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in median_list:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    adjusted= cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "    # Display the original and adjusted images side-by-side\n",
    "    cv2.imshow('Original', img)\n",
    "    cv2.imshow('Adjusted', adjusted)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in median_list:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "\n",
    "    # Apply ACE\n",
    "    ace_img = clahe.apply(img)\n",
    "    ace_img= cv2.cvtColor(ace_img, cv2.COLOR_GRAY2RGB)\n",
    "    cv2.imshow('Edges',ace_img )\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nmeans for image 1 \n",
    "nmeans_1 = cv2.fastNlMeansDenoisingColored(im01)\n",
    "cv2.imwrite(\"nmeans_1.jpg\", nmeans_1)\n",
    "\n",
    "#Bilateral for image 1 \n",
    "bilat_1 = cv2.bilateralFilter((im01),3,75,75)\n",
    "cv2.imwrite(\"bilat_1.jpg\", bilat_1)\n",
    "\n",
    "#Gaussian on image 1 \n",
    "gaussian_1 = cv2.GaussianBlur(im01, (3,3), 30)\n",
    "cv2.imwrite(\"gaussian_1.jpg\", gaussian_1)\n",
    "\n",
    "#exp function\n",
    "import math\n",
    "def exponential_transform(image, c, alpha):\n",
    "    for i in range(0, image.shape[1]):  # image width\n",
    "        for j in range(0, image.shape[0]):  # image height\n",
    "\n",
    "            # compute exponential transform\n",
    "\n",
    "            image[j, i] = int(c * (math.pow(1 + alpha, image[j, i]) - 1))\n",
    "    return image\n",
    "scaled_1= cv2.resize(im01, ((int(im01.shape[1] * 0.6)),int(im01.shape[0] * 0.6)), interpolation=cv2.INTER_AREA)\n",
    "gray_scaled_im01 = cv2.cvtColor(scaled_1, cv2.COLOR_BGR2GRAY)\n",
    "EXP1 = exponential_transform(gray_scaled_im01, 130, 0.003)\n",
    "colored_EXP1 = cv2.cvtColor(EXP1, cv2.COLOR_GRAY2BGR)\n",
    "cv2.imwrite(\"EXPt1.png\", colored_EXP1)\n",
    "\n",
    "# gamma correction \n",
    "import numpy as np\n",
    "gamma_1 = np.array(255*(1/255)**1.4,dtype='uint8')\n",
    "cv2.imwrite(\"gamma_1.png\", gamma_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a4a32836cfcf09d0be1b60e3fed54fd94725d7f18611df689f0a2f723a72c4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
